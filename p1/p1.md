# CSC2233 - Project 1 - Mitigating Blktrace Overheads on SSDs

#Pre-requisites

- Sound knowledge of blktrace/blkparse tool
- creating, formatting, and mounting file systems
- linux utilities (cut, grep, sed)
- large data processing (few GBs) using numpy/python/shell scripting

# Objective

This project has two parts. The first part evaluates the overheads of blktrace while running workloads on applications and identifies for what workloads the performance of the application reduces when blktrace is enabled. The second and most important part of the project will be to come up with ways to reduce the blocktrace overheads. 

The figure below show how the storage stack is aligned.
#![](arch.jpg)

# Checkpoint 1 Mid Term Checkpoint (Mid-Feb)

For this checkpoint you will install and run different microbenchmarks with blktrace. The goal is to understand where blktrace overheads mostly come from and identify ideas for combatting these overheads. 

- Install the following two microbenchmarks for your system:
1. dd
2. Fio

- Run the microbenchmarks using different options on ext4, btrfs and f2fs file systems. Each of the microbenchmarks should run for the file system on HDD and SSD and if possible, and in-memory block device [ramdisk](https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux). Ensure that you are writing large amount of data to your disk so that disk is being stressed. One way to do this would be to use multiple threads for dd, fio and filebench. The goal is to utilize full bandwidth of the HDD or SSD.
- Run each of the microbenchmarks again,  but this time, enable blktrace.
- Quantify the overhead - does it take more time to complete a specific workload (fio)? does it cause drop in performance (time to complete a dd operation or IOPS/Bandwidth for fio)? Draw graphs to show the relative performance for one or more microbenchmark configurations.
- Identify the workload configurations that has a high blktrace overhead for the application you choose above.
- Use profiling tools to identify where overheads come from - CPU and/or memory and/or disk. Your analysis should narrow down the cause for blktrace overhead.

# Checkpoint 2 End Term Checkpoint (End of March)

- Identify and implement ways to reduce blocktrace overhead. Some ideas:
1. Can we reduce the granularity at which blktrace logs blocks - e.g. coalesce multiple log messages into a single log? This way the size of the blktrace log can be reduced considerably.
2. Can we directly (online) collect and compute statistics of interest, rather than dumping everything to disk. Or maybe use sampling? See [this](https://www.usenix.org/system/files/conference/hotstorage16/hotstorage16_yadgar.pdf) paper for interesting statistics. Take a look at the [CounterStacks](https://www.usenix.org/node/186182) for using data structures to keep track of an interesting statistics. Take a look at the [Shards paper](https://www.usenix.org/system/files/conference/fast15/fast15-paper-waldspurger.pdf) for an example using sampling.
3. Redirect logging of the messages in [ramdisk](https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux) for a short period of time, after which log messages permanently to disk.

# Checkpoint 3 Final Report
- You should submit 2 reports

## Main Report (Latex + pdf)
1. A pdf document describing your application, different workload configurations explored, blktrace overheads observed in each configuration, and steps taken to reduce this overhead.

## Setup Instructions (Latex + pdf / markdown) and Code
2. A zip file of a document describing your application, setup instructions so that another student can repeat your experiments and recreate your results, a link to your blktrace files. all blocktrace analysis code/scripts - documented and commented - with your name.
