# CSC494 - Project 1 - Mitigating Blktrace Overheads

**Pre-requisites**

- Sound knowledge of blktrace/blkparse tool
- creating, formatting, and mounting file systems
- linux utilities (cut, grep, sed)
- large data processing (few GBs) using numpy/python/shell scripting
- installing and setting up workloads like YCSB, TPCC
- installing and setting up applications like Spark, Cassandra, MySQL

# Objective

This project evaluates the overheads of blktrace while running workloads on applications. The goal is to first identify for what workloads the performance of the application reduces when blktrace is enabled. The next part of the project will explore ways to reduce the blocktrace overheads.

# Checkpoint 1 Mid Term Checkpoint (Feb 28th)
- Choose one or more micro-benchmarks for your system:
1. dd
2. fio
3. filebench (mail server, web server and file server)

- Run the workload for 1 hour or more on ext4, btrfs and f2fs file systems. Run the workload for an application installed on HDD and SSD and if possible, and in-memory block device [ramdisk](https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux). Ensure that you are writing large amount of data to your disk so that disk is being stressed. One way to do this would be to use multiple threads for dd/fio. The goal is to utilize full bandwidth of the HDD or SSD.
- Run the same workload with blktrace enabled.
- Quantify the overhead - does it take more time to complete a specific workload? does it cause drop in performance? By how much?
- Finalize an application and a workload, and complete installation for both and get instructors approval.
1. [OLTP](https://github.com/oltpbenchmark/oltpbench) + MySQL
2. [YCSB](https://github.com/brianfrankcooper/YCSB/wiki) + [Cassandra](https://github.com/apache/cassandra)
3. [Spark](https://github.com/apache/spark) + [Stanford Large Network Data set Collection](https://snap.stanford.edu/data/)
4. [Ceph](https://ceph.com/) + [COSBench](https://github.com/intel-cloud/cosbench)

# Checkpoint 2 End Term Checkpoint (March 31st)
- Identify the workload configuration that has a high blktrace overhead for the application you choose above.
- Identify ways to reduce this overhead. some ideas:
1. can we reduce the granularity at which blktrace logs blocks - e.g. coalesce multiple log messages into a single log?
2. redirect logging of the messages in [ramdisk](https://www.jamescoyle.net/how-to/943-create-a-ram-disk-in-linux) for a short period of time, after which flush the log messages permanently to disk.

# Checkpoint 3 Final Report
- You should submit 2 reports

## Main Report (Latex + pdf)
1. A pdf document describing your application, different workload configurations explored, blktrace overheads observed in each configuration, and steps taken to reduce this overhead.

## Setup Instructions (Latex + pdf / markdown)
2. A document describing your application, setup instructions so that another student can repeat your experiments and recreate your results, a link to your blktrace files.
